{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# here's where i will define and package my \n",
    "# layer space. \n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, add, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_block(filter_depth, filter_size, pool_size, activation, inputs):\n",
    "    x = BatchNormalization()(inputs)\n",
    "    x = Convolution2D(filter_depth, filter_size, activation=activation)(x)\n",
    "    x = MaxPooling2D(pool_size=pool_size)(x)\n",
    "    return x\n",
    "\n",
    "def dense_block(units, activation, drop_prob, inputs):\n",
    "    x = BatchNormalization()(inputs)\n",
    "    x = Dense(units, activation=activation)(x)\n",
    "    x = Dropout(drop_prob)(x)\n",
    "    return x\n",
    "\n",
    "def resnet_block(filter_depth, filter_size, pool_size, activation, inputs):\n",
    "    x = BatchNormalization()(inputs)\n",
    "    x = Convolution2D(filter_depth, (1,1), activation=activation)(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Convolution2D(filter_depth, filter_size, activation=activation, padding='same')(x)\n",
    "    \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Convolution2D(filter_depth, (1,1))(x)\n",
    "    \n",
    "    shortcut = Convolution2D(filter_depth, (1,1))(inputs)\n",
    "    shortcut = BatchNormalization()(shortcut)\n",
    "    \n",
    "    x = add([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semi randomly create a model, each input is of format:\n",
    "# [model, (range), (range)] where ranges are for the hyperparameters\n",
    "# -> range = (range_start, range_end, range_incrementer), range_incrementer\n",
    "# is a method (labmda func) that tells you how to increment that hyper param\n",
    "def rand_model(*args, blocks=1, in_shape):\n",
    "    m = Input(shape=in_shape)\n",
    "    inputs = m\n",
    "    for i in range(blocks):\n",
    "        params = []\n",
    "        block = np.random.choice(args,1)\n",
    "        args \n",
    "        for param_options in block[0][1:]:\n",
    "            ix = np.random.choice(len(param_options),1)\n",
    "            params.append(param_options[ix[0]])\n",
    "        m = block[0][0](*params, inputs=m)\n",
    "    \n",
    "    output = dense_block(1, 'sigmoid', 0, m)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    return model\n",
    "    \n",
    "conv_param_space = [conv_block, \n",
    "                    [4,256,512,1024,2048],\n",
    "                    [(1,1),(2,2),(3,3),(4,4),(5,5)],\n",
    "                    [(2,2),(3,3)],\n",
    "                    ['relu']\n",
    "                    ]\n",
    "resnet_param_space = [resnet_block,\n",
    "                    [16,32,64,128,256],\n",
    "                    [(1,1),(2,2),(3,3),(4,4),(5,5)],\n",
    "                    [(2,2),(3,3)],\n",
    "                    ['relu']\n",
    "                    ]\n",
    "dense_param_space = [dense_block,\n",
    "                     [256,512,1024,2048],\n",
    "                     ['relu'],\n",
    "                     [0.25,0.35,0.45,0.55,0.65,0.75]\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make 5 2block models\n",
    "models = []\n",
    "for i in range(5):\n",
    "    models.append(rand_model(conv_param_space, resnet_param_space, dense_param_space, blocks=2, in_shape=(128,128,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for \n",
    "script = '''#!/bin/bash\n",
    "\n",
    "#SBATCH --job-name=jupyterGPU\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --mem=64GB\n",
    "#SBATCH --time=100:00:00\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --job-name=optimizing_model\n",
    "#SBATCH --mail-type=END\n",
    "#SBATCH --mail-user=yns207@nyu.edu\n",
    "#SBATCH --output=/scratch/yns207/job_logs/optimizing_model_%j.out\n",
    "#SBATCH --error=/scratch/yns207/job_logs/optimizing_model_%j.err\n",
    "#SBATCH --get-user-env\n",
    "\n",
    "module purge\n",
    "module load cuda\n",
    "module load cudnn\n",
    "\n",
    "unset XDG_RUNTIME_DIR\n",
    "if [ \"$SLURM_JOBTMP\" != \"\" ]; then\n",
    "    export XDG_RUNTIME_DIR=$SLURM_JOBTMP\n",
    "fi\n",
    "\n",
    "echo \"optimizing model...\"\n",
    "time $HOME/anaconda3/envs/smappcollector/bin/python $HOME/nbs/machine_learning/gpu-rancher/fit_model.py -i {}\n",
    "echo \"done\"\n",
    "'''.format()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
