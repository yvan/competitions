{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# todo\n",
    "\n",
    "1. download data and split the data based on the specs of the competition\n",
    "2. import keras and create a basic model\n",
    "3. create a better model\n",
    "4. generate predictions\n",
    "5. save predictions and submit to kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# download statefarm data, split train,valid,sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yns207/nbs/machine_learning\n"
     ]
    }
   ],
   "source": [
    "%cd /home/yns207/nbs/machine_learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yns207/nbs/machine_learning /scratch/yns207/data_statefarm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "CUR_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join('/scratch', 'yns207', 'data_statefarm')\n",
    "print(CUR_DIR, DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/yns207/data_statefarm\n",
      "downloading https://www.kaggle.com/c/state-farm-distracted-driver-detection/download/sample_submission.csv.zip\n",
      "\n",
      "sample_submission.csv.zip 100% |####################| Time: 0:00:00 465.9 KiB/s\n",
      "downloading https://www.kaggle.com/c/state-farm-distracted-driver-detection/download/imgs.zip\n",
      "\n",
      "imgs.zip 100% |#####################################| Time: 0:04:29  15.2 MiB/s\n",
      "downloading https://www.kaggle.com/c/state-farm-distracted-driver-detection/download/driver_imgs_list.csv.zip\n",
      "\n",
      "driver_imgs_list.csv.zip 100% |#####################| Time: 0:00:00 378.6 KiB/s\n"
     ]
    }
   ],
   "source": [
    "%mkdir $DATA_DIR\n",
    "%cd $DATA_DIR\n",
    "!kg config -g -c 'state-farm-distracted-driver-detection'\n",
    "!kg download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/yns207/data_statefarm\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_DIR\n",
    "!unzip -q driver_imgs_list.csv.zip\n",
    "!unzip -q imgs.zip\n",
    "!unzip -q sample_submission.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4,1G\n",
      "drwxr-x---  4 yns207 yns207 4,0K 16 mai   11:52 \u001b[0m\u001b[38;5;27m.\u001b[0m/\n",
      "drwx------  6 yns207 users  4,0K 13 mai   21:40 \u001b[38;5;27m..\u001b[0m/\n",
      "-rw-r--r--  1 yns207 yns207 480K  7 avril  2016 driver_imgs_list.csv\n",
      "-rw-r-----  1 yns207 yns207  93K 13 mai   21:44 \u001b[38;5;9mdriver_imgs_list.csv.zip\u001b[0m\n",
      "-rw-r-----  1 yns207 yns207 4,0G 13 mai   21:44 \u001b[38;5;9mimgs.zip\u001b[0m\n",
      "-rw-r--r--  1 yns207 yns207 4,1M 29 mars   2016 sample_submission.csv\n",
      "-rw-r-----  1 yns207 yns207 207K 13 mai   21:40 \u001b[38;5;9msample_submission.csv.zip\u001b[0m\n",
      "drwxr-xr-x  2 yns207 yns207 4,4M 31 déc.   2015 \u001b[38;5;27mtest\u001b[0m/\n",
      "drwxr-xr-x 12 yns207 yns207 4,0K 29 mars   2016 \u001b[38;5;27mtrain\u001b[0m/\n",
      "total 1,4M\n",
      "drwxr-xr-x 12 yns207 yns207 4,0K 29 mars   2016 \u001b[0m\u001b[38;5;27m.\u001b[0m/\n",
      "drwxr-x---  4 yns207 yns207 4,0K 16 mai   11:52 \u001b[38;5;27m..\u001b[0m/\n",
      "drwxr-xr-x  2 yns207 yns207 152K 31 déc.   2015 \u001b[38;5;27mc0\u001b[0m/\n",
      "drwxr-xr-x  2 yns207 yns207 124K 31 déc.   2015 \u001b[38;5;27mc1\u001b[0m/\n",
      "drwxr-xr-x  2 yns207 yns207 132K 31 déc.   2015 \u001b[38;5;27mc2\u001b[0m/\n",
      "drwxr-xr-x  2 yns207 yns207 132K 31 déc.   2015 \u001b[38;5;27mc3\u001b[0m/\n",
      "drwxr-xr-x  2 yns207 yns207 128K 31 déc.   2015 \u001b[38;5;27mc4\u001b[0m/\n",
      "drwxr-xr-x  2 yns207 yns207 144K 31 déc.   2015 \u001b[38;5;27mc5\u001b[0m/\n",
      "drwxr-xr-x  2 yns207 yns207 132K 31 déc.   2015 \u001b[38;5;27mc6\u001b[0m/\n",
      "drwxr-xr-x  2 yns207 yns207 132K 31 déc.   2015 \u001b[38;5;27mc7\u001b[0m/\n",
      "drwxr-xr-x  2 yns207 yns207 128K 31 déc.   2015 \u001b[38;5;27mc8\u001b[0m/\n",
      "drwxr-xr-x  2 yns207 yns207 124K 31 déc.   2015 \u001b[38;5;27mc9\u001b[0m/\n",
      "total 3,3G\n",
      "drwxr-xr-x 2 yns207 yns207 4,4M 31 déc.   2015 \u001b[0m\u001b[38;5;27m.\u001b[0m/\n",
      "drwxr-x--- 4 yns207 yns207 4,0K 16 mai   11:52 \u001b[38;5;27m..\u001b[0m/\n",
      "-rw-r--r-- 1 yns207 yns207  38K 31 déc.   2015 \u001b[38;5;13mimg_100000.jpg\u001b[0m\n",
      "-rw-r--r-- 1 yns207 yns207  42K 31 déc.   2015 \u001b[38;5;13mimg_100001.jpg\u001b[0m\n",
      "-rw-r--r-- 1 yns207 yns207  44K 31 déc.   2015 \u001b[38;5;13mimg_100002.jpg\u001b[0m\n",
      "-rw-r--r-- 1 yns207 yns207  48K 31 déc.   2015 \u001b[38;5;13mimg_100003.jpg\u001b[0m\n",
      "-rw-r--r-- 1 yns207 yns207  38K 31 déc.   2015 \u001b[38;5;13mimg_100004.jpg\u001b[0m\n",
      "-rw-r--r-- 1 yns207 yns207  42K 31 déc.   2015 \u001b[38;5;13mimg_100005.jpg\u001b[0m\n",
      "-rw-r--r-- 1 yns207 yns207  38K 31 déc.   2015 \u001b[38;5;13mimg_100007.jpg\u001b[0m\n",
      "-rw-r--r-- 1 yns207 yns207  48K 31 déc.   2015 \u001b[38;5;13mimg_100008.jpg\u001b[0m\n",
      "-rw-r--r-- 1 yns207 yns207  42K 31 déc.   2015 \u001b[38;5;13mimg_100009.jpg\u001b[0m\n",
      "-rw-r--r-- 1 yns207 yns207  45K 31 déc.   2015 \u001b[38;5;13mimg_100010.jpg\u001b[0m\n",
      "-rw-r--r-- 1 yns207 yns207  39K 31 déc.   2015 \u001b[38;5;13mimg_100011.jpg\u001b[0m\n",
      "-rw-r--r-- 1 yns207 yns207  46K 31 déc.   2015 \u001b[38;5;13mimg_100012.jpg\u001b[0m\n",
      "-rw-r--r-- 1 yns207 yns207  35K 31 déc.   2015 \u001b[38;5;13mimg_100013.jpg\u001b[0m\n",
      "-rw-r--r-- 1 yns207 yns207  42K 31 déc.   2015 \u001b[38;5;13mimg_100014.jpg\u001b[0m\n",
      "-rw-r--r-- 1 yns207 yns207  42K 31 déc.   2015 \u001b[38;5;13mimg_100016.jpg\u001b[0m\n",
      "-rw-r--r-- 1 yns207 yns207  37K 31 déc.   2015 \u001b[38;5;13mimg_100017.jpg\u001b[0m\n",
      "-rw-r--r-- 1 yns207 yns207  41K 31 déc.   2015 \u001b[38;5;13mimg_100018.jpg\u001b[0m\n",
      "-rw-r--r-- 1 yns207 yns207  45K 31 déc.   2015 \u001b[38;5;13mimg_100019.jpg\u001b[0m\n",
      "-rw-r--r-- 1 yns207 yns207  39K 31 déc.   2015 \u001b[38;5;13mimg_10001.jpg\u001b[0m\n",
      "-rw-r--r-- 1 yns207 yns207  38K 31 déc.   2015 \u001b[38;5;13mimg_100020.jpg\u001b[0m\n",
      "-rw-r--r-- 1 yns207 yns207  51K 31 déc.   2015 \u001b[38;5;13mimg_100022.jpg\u001b[0m\n",
      "-rw-r--r-- 1 yns207 yns207  34K 31 déc.   2015 \u001b[38;5;13mimg_100023.jpg\u001b[0m\n",
      "ls: erreur d'écriture\n"
     ]
    }
   ],
   "source": [
    "%ls -lah $DATA_DIR\n",
    "%ls -lah $DATA_DIR/train | head -n 25\n",
    "%ls -lah $DATA_DIR/test | head -n 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 105M\r\n",
      "drwxr-xr-x  2 yns207 yns207 152K 31 déc.   2015 \u001b[0m\u001b[38;5;27m.\u001b[0m/\r\n",
      "drwxr-xr-x 12 yns207 yns207 4,0K 29 mars   2016 \u001b[38;5;27m..\u001b[0m/\r\n",
      "-rw-r--r--  1 yns207 yns207  49K 31 déc.   2015 \u001b[38;5;13mimg_100026.jpg\u001b[0m\r\n",
      "-rw-r--r--  1 yns207 yns207  37K 31 déc.   2015 \u001b[38;5;13mimg_10003.jpg\u001b[0m\r\n",
      "-rw-r--r--  1 yns207 yns207  40K 31 déc.   2015 \u001b[38;5;13mimg_100050.jpg\u001b[0m\r\n",
      "-rw-r--r--  1 yns207 yns207  40K 31 déc.   2015 \u001b[38;5;13mimg_100074.jpg\u001b[0m\r\n",
      "-rw-r--r--  1 yns207 yns207  40K 31 déc.   2015 \u001b[38;5;13mimg_10012.jpg\u001b[0m\r\n",
      "-rw-r--r--  1 yns207 yns207  45K 31 déc.   2015 \u001b[38;5;13mimg_100145.jpg\u001b[0m\r\n",
      "-rw-r--r--  1 yns207 yns207  40K 31 déc.   2015 \u001b[38;5;13mimg_100191.jpg\u001b[0m\r\n",
      "-rw-r--r--  1 yns207 yns207  43K 31 déc.   2015 \u001b[38;5;13mimg_100257.jpg\u001b[0m\r\n",
      "-rw-r--r--  1 yns207 yns207  28K 31 déc.   2015 \u001b[38;5;13mimg_100312.jpg\u001b[0m\r\n",
      "-rw-r--r--  1 yns207 yns207  38K 31 déc.   2015 \u001b[38;5;13mimg_100337.jpg\u001b[0m\r\n",
      "-rw-r--r--  1 yns207 yns207  42K 31 déc.   2015 \u001b[38;5;13mimg_100456.jpg\u001b[0m\r\n",
      "-rw-r--r--  1 yns207 yns207  46K 31 déc.   2015 \u001b[38;5;13mimg_10053.jpg\u001b[0m\r\n",
      "-rw-r--r--  1 yns207 yns207  40K 31 déc.   2015 \u001b[38;5;13mimg_100542.jpg\u001b[0m\r\n",
      "-rw-r--r--  1 yns207 yns207  38K 31 déc.   2015 \u001b[38;5;13mimg_100598.jpg\u001b[0m\r\n",
      "-rw-r--r--  1 yns207 yns207  40K 31 déc.   2015 \u001b[38;5;13mimg_1005.jpg\u001b[0m\r\n",
      "-rw-r--r--  1 yns207 yns207  40K 31 déc.   2015 \u001b[38;5;13mimg_100605.jpg\u001b[0m\r\n",
      "-rw-r--r--  1 yns207 yns207  43K 31 déc.   2015 \u001b[38;5;13mimg_100656.jpg\u001b[0m\r\n",
      "-rw-r--r--  1 yns207 yns207  39K 31 déc.   2015 \u001b[38;5;13mimg_100665.jpg\u001b[0m\r\n",
      "-rw-r--r--  1 yns207 yns207  40K 31 déc.   2015 \u001b[38;5;13mimg_100796.jpg\u001b[0m\r\n",
      "-rw-r--r--  1 yns207 yns207  39K 31 déc.   2015 \u001b[38;5;13mimg_100824.jpg\u001b[0m\r\n",
      "-rw-r--r--  1 yns207 yns207  46K 31 déc.   2015 \u001b[38;5;13mimg_100828.jpg\u001b[0m\r\n",
      "-rw-r--r--  1 yns207 yns207  40K 31 déc.   2015 \u001b[38;5;13mimg_100922.jpg\u001b[0m\r\n",
      "ls: erreur d'écriture\r\n"
     ]
    }
   ],
   "source": [
    "%ls -lah $DATA_DIR/train/c0 | head -n 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%mkdir $DATA_DIR/test/uknown\n",
    "%mv $DATA_DIR/test/*.jpg $DATA_DIR/test/uknown/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/yns207/data_statefarm\n"
     ]
    }
   ],
   "source": [
    "#load driver info when craeting validation set so that\n",
    "#no one driver appears in both valid and train sets\n",
    "#we want this to be the case becaus on kaggle they say that no\n",
    "#one driver is both in the train and test sets and we want to mimic this\n",
    "\n",
    "import pandas as pd\n",
    "%cd $DATA_DIR\n",
    "driver_imgs = pd.read_csv('driver_imgs_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>classname</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_44733.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_72999.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_25094.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_69092.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_92629.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_3370.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_67639.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_58560.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_35779.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_10012.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject classname            img\n",
       "0    p002        c0  img_44733.jpg\n",
       "1    p002        c0  img_72999.jpg\n",
       "2    p002        c0  img_25094.jpg\n",
       "3    p002        c0  img_69092.jpg\n",
       "4    p002        c0  img_92629.jpg\n",
       "5    p002        c0   img_3370.jpg\n",
       "6    p002        c0  img_67639.jpg\n",
       "7    p002        c0  img_58560.jpg\n",
       "8    p002        c0  img_35779.jpg\n",
       "9    p002        c0  img_10012.jpg"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver_imgs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['p047', 'p014', 'p035', 'p051', 'p075']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "num_users = len(driver_imgs['subject'].unique())\n",
    "sample_users = random.sample(list(driver_imgs['subject'].unique()) ,5)\n",
    "sample_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/yns207/data_statefarm\n"
     ]
    }
   ],
   "source": [
    "# make valid folder tree\n",
    "%cd $DATA_DIR\n",
    "!for i in {0..9}; do mkdir -p valid/c$i; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/yns207/data_statefarm\n"
     ]
    }
   ],
   "source": [
    "# take the sample users and move all their images to valid\n",
    "%cd $DATA_DIR\n",
    "for index,row in driver_imgs[driver_imgs['subject'].isin(sample_users)].iterrows():\n",
    "    old = os.path.join('train', row['classname'], row['img'])\n",
    "    new = os.path.join('valid', row['classname'], row['img'])\n",
    "    os.rename(old, new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/yns207/data_statefarm\n",
      "c0\n",
      "540\n",
      "c1\n",
      "440\n",
      "c2\n",
      "438\n",
      "c3\n",
      "440\n",
      "c4\n",
      "447\n",
      "c5\n",
      "443\n",
      "c6\n",
      "456\n",
      "c7\n",
      "411\n",
      "c8\n",
      "320\n",
      "c9\n",
      "388\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_DIR\n",
    "!for i in {0..9}; do echo c$i; ls -lah valid/c$i | wc -l; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/yns207/data_statefarm\n"
     ]
    }
   ],
   "source": [
    "# now create a sample of the training and valid sets\n",
    "%cd $DATA_DIR\n",
    "!for i in {0..9}; do mkdir -p sample/train/c$i; mkdir -p sample/valid/c$i; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/yns207/data_statefarm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from shutil import copyfile\n",
    "from glob import glob\n",
    "\n",
    "%cd $DATA_DIR\n",
    "\n",
    "g_train = np.random.permutation(glob(os.path.join('train', 'c?/*jpg')))\n",
    "g_valid = np.random.permutation(glob(os.path.join('valid', 'c?/*jpg')))\n",
    "\n",
    "for i in range(1500):\n",
    "    copyfile(g_train[i], os.path.join(DATA_DIR, 'sample', g_train[i]))\n",
    "for i in range(1000):\n",
    "    copyfile(g_valid[i], os.path.join(DATA_DIR, 'sample', g_valid[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%mkdir -p $DATA_DIR/results\n",
    "%mkdir -p $DATA_DIR/sample/results $DATA_DIR/sample/test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import keras and make a basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from theano.sandbox import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import FileLink\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import PIL\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.preprocessing import image\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/yns207/data_statefarm/sample/train\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = os.path.join(DATA_DIR, 'sample')\n",
    "test_path = os.path.join(path, 'test')\n",
    "models_path = os.path.join(path, 'results')\n",
    "train_path = os.path.join(path, 'train')\n",
    "valid_path = os.path.join(path, 'valid')\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1500 images belonging to 10 classes.\n",
      "Found 1000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "gen = image.ImageDataGenerator()\n",
    "tr_batches = gen.flow_from_directory(train_path, target_size=(224,224), class_mode='categorical', shuffle=True, batch_size=batch_size)\n",
    "va_batches = gen.flow_from_directory(valid_path, target_size=(224,224), class_mode='categorical', shuffle=False, batch_size=batch_size*2)\n",
    "# te_batches = gen.flow_from_directory(test_path, target_size=(224,224), class_mode='categorical', shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "va_classes = va_batches.classes\n",
    "tr_classes = tr_batches.classes\n",
    "va_labels = to_categorical(va_classes)\n",
    "tr_labels = to_categorical(tr_classes)\n",
    "va_filenames = va_batches.filenames\n",
    "tr_filenames = tr_batches.filenames\n",
    "# te_filenames = te_batches.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    BatchNormalization(axis=1, input_shape=(3,224,224)),\n",
    "    Flatten(),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "23/23 [==============================] - 119s - loss: 12.3475 - acc: 0.1760 - val_loss: 13.8419 - val_acc: 0.1366\n",
      "Epoch 2/2\n",
      "23/23 [==============================] - 70s - loss: 12.8302 - acc: 0.1975 - val_loss: 14.1261 - val_acc: 0.1234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ab8c2d99b70>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(tr_batches, \n",
    "                    steps_per_epoch=tr_batches.n//batch_size, \n",
    "                    validation_data=va_batches, \n",
    "                    validation_steps=va_batches.n//batch_size,\n",
    "                    epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_4 (Batch (None, 3, 224, 224)       12        \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 150528)            0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1505290   \n",
      "=================================================================\n",
      "Total params: 1,505,302\n",
      "Trainable params: 1,505,296\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "the model is stuck, its likely predicting 1-2 classes with high accuracy \n",
    "and giving all the other classes 0 to try to minimize its loss,\n",
    "default learning rate on Adam optimizer is too large\n",
    "'''\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "24/24 [==============================] - 36s - loss: 5.0429 - acc: 0.2699 - val_loss: 9.5460 - val_acc: 0.2090\n",
      "Epoch 2/2\n",
      "24/24 [==============================] - 26s - loss: 1.5623 - acc: 0.6130 - val_loss: 5.6561 - val_acc: 0.2780\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ab8ccc16f98>"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try a lower learning rate at the start\n",
    "model = Sequential([\n",
    "    BatchNormalization(axis=1, input_shape=(3,224,224)),\n",
    "    Flatten(),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(tr_batches, \n",
    "                    steps_per_epoch=(tr_batches.n//batch_size)+1, \n",
    "                    validation_data=va_batches, \n",
    "                    validation_steps=(va_batches.n//batch_size)+1,\n",
    "                    epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "24/24 [==============================] - 38s - loss: 0.5130 - acc: 0.8511 - val_loss: 4.0271 - val_acc: 0.3250\n",
      "Epoch 2/4\n",
      "24/24 [==============================] - 26s - loss: 0.2268 - acc: 0.9365 - val_loss: 3.4260 - val_acc: 0.3930\n",
      "Epoch 3/4\n",
      "24/24 [==============================] - 29s - loss: 0.1249 - acc: 0.9808 - val_loss: 2.9233 - val_acc: 0.3740\n",
      "Epoch 4/4\n",
      "24/24 [==============================] - 27s - loss: 0.0723 - acc: 0.9961 - val_loss: 2.7301 - val_acc: 0.3700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ab8ccb1fac8>"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ok now train with a slightly higher learning rate\n",
    "model.optimizer.lr=0.001\n",
    "model.fit_generator(tr_batches, \n",
    "                    steps_per_epoch=(tr_batches.n//batch_size)+1, \n",
    "                    validation_data=va_batches, \n",
    "                    validation_steps=(va_batches.n//batch_size)+1,\n",
    "                    epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "rand_batches = gen.flow_from_directory(valid_path, target_size=(224,224), class_mode='categorical', shuffle=True, batch_size=batch_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.7 ,  0.37],\n",
       "       [ 2.7 ,  0.37],\n",
       "       [ 2.72,  0.37],\n",
       "       [ 2.67,  0.37],\n",
       "       [ 2.79,  0.37],\n",
       "       [ 2.71,  0.38],\n",
       "       [ 2.76,  0.37],\n",
       "       [ 2.72,  0.37],\n",
       "       [ 2.74,  0.37],\n",
       "       [ 2.75,  0.37]])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use our random batches to show that were \n",
    "# hovering around .38 validation accuracy\n",
    "# apparently an improvement of more tahn 3% here\n",
    "# is 'non random'\n",
    "val_res = [model.evaluate_generator(rand_batches, rand_batches.n // (batch_size*2)) for i in range(10)]\n",
    "np.round(val_res, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make better model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "24/24 [==============================] - 25s - loss: 4.8744 - acc: 0.2856 - val_loss: 9.5252 - val_acc: 0.2400\n",
      "Epoch 2/2\n",
      "24/24 [==============================] - 25s - loss: 2.9543 - acc: 0.6059 - val_loss: 4.5971 - val_acc: 0.3310\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ab8dcca52e8>"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add l2 regularization to the model\n",
    "model = Sequential([\n",
    "        BatchNormalization(axis=1, input_shape=(3,224,224)),\n",
    "        Flatten(),\n",
    "        Dense(10, activation='softmax', kernel_regularizer=l2(0.01))\n",
    "])\n",
    "\n",
    "model.compile(Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(tr_batches, \n",
    "                    steps_per_epoch=(tr_batches.n//batch_size)+1, \n",
    "                    validation_data=va_batches, \n",
    "                    validation_steps=(va_batches.n//batch_size)+1,\n",
    "                    epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "24/24 [==============================] - 32s - loss: 2.4035 - acc: 0.7617 - val_loss: 5.7990 - val_acc: 0.2490\n",
      "Epoch 2/4\n",
      "24/24 [==============================] - 28s - loss: 2.0709 - acc: 0.8482 - val_loss: 4.9713 - val_acc: 0.2910\n",
      "Epoch 3/4\n",
      "24/24 [==============================] - 31s - loss: 1.9489 - acc: 0.8860 - val_loss: 4.3251 - val_acc: 0.3500\n",
      "Epoch 4/4\n",
      "24/24 [==============================] - 30s - loss: 1.9589 - acc: 0.8888 - val_loss: 4.2250 - val_acc: 0.3550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ab8dcca5fd0>"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr=0.001\n",
    "model.fit_generator(tr_batches, \n",
    "                    steps_per_epoch=(tr_batches.n//batch_size)+1, \n",
    "                    validation_data=va_batches, \n",
    "                    validation_steps=(va_batches.n//batch_size)+1,\n",
    "                    epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uh its worse meh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "24/24 [==============================] - 89s - loss: 2.0835 - acc: 0.3756 - val_loss: 10.7966 - val_acc: 0.1530\n",
      "Epoch 2/2\n",
      "24/24 [==============================] - 82s - loss: 1.1836 - acc: 0.6766 - val_loss: 5.9594 - val_acc: 0.1850\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 85s - loss: 0.6481 - acc: 0.8827 - val_loss: 3.1254 - val_acc: 0.2730\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 59s - loss: 0.3647 - acc: 0.9573 - val_loss: 2.3699 - val_acc: 0.3190\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 78s - loss: 0.2061 - acc: 0.9894 - val_loss: 1.8070 - val_acc: 0.4280\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 78s - loss: 0.1329 - acc: 0.9920 - val_loss: 1.7206 - val_acc: 0.4520\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 58s - loss: 0.0835 - acc: 1.0000 - val_loss: 1.7591 - val_acc: 0.4670\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ab8dfe50978>"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add a single hidden layer\n",
    "model = Sequential([\n",
    "    BatchNormalization(axis=1, input_shape=(3,224,224)),\n",
    "    Flatten(),\n",
    "    Dense(100, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(tr_batches, \n",
    "                    steps_per_epoch=(tr_batches.n//batch_size)+1, \n",
    "                    validation_data=va_batches, \n",
    "                    validation_steps=(va_batches.n//batch_size)+1,\n",
    "                    epochs=2)\n",
    "model.optimizer.lr = 0.01\n",
    "model.fit_generator(tr_batches, \n",
    "                    steps_per_epoch=(tr_batches.n//batch_size)+1, \n",
    "                    validation_data=va_batches, \n",
    "                    validation_steps=(va_batches.n//batch_size)+1,\n",
    "                    epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# well that turned out ok, but were stuck at 100% training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv1(batches):\n",
    "    model = Sequential([\n",
    "            BatchNormalization(axis=1, input_shape=(3,224,224)),\n",
    "            Convolution2D(32,(3,3), activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "            Convolution2D(64,(3,3), activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "            Flatten(),\n",
    "            Dense(200, activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dense(10, activation='softmax')\n",
    "        ])\n",
    "\n",
    "    model.compile(Adam(lr=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit_generator(tr_batches, \n",
    "                    steps_per_epoch=(tr_batches.n//batch_size)+1, \n",
    "                    validation_data=va_batches, \n",
    "                    validation_steps=(va_batches.n//batch_size)+1,\n",
    "                    epochs=2)\n",
    "    model.optimizer.lr = 0.01\n",
    "    model.fit_generator(tr_batches, \n",
    "                        steps_per_epoch=(tr_batches.n//batch_size)+1, \n",
    "                        validation_data=va_batches, \n",
    "                        validation_steps=(va_batches.n//batch_size)+1,\n",
    "                        epochs=5)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yns207/anaconda3/envs/keras-py3/lib/python3.5/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  after removing the cwd from sys.path.\n",
      "/home/yns207/anaconda3/envs/keras-py3/lib/python3.5/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "24/24 [==============================] - 57s - loss: 2.2827 - acc: 0.2601 - val_loss: 2.5020 - val_acc: 0.1180\n",
      "Epoch 2/2\n",
      "24/24 [==============================] - 85s - loss: 1.2738 - acc: 0.6276 - val_loss: 2.3498 - val_acc: 0.1460\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 61s - loss: 0.7765 - acc: 0.8305 - val_loss: 2.3097 - val_acc: 0.1970\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 68s - loss: 0.4928 - acc: 0.9321 - val_loss: 2.3182 - val_acc: 0.1920\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 98s - loss: 0.3318 - acc: 0.9661 - val_loss: 2.3228 - val_acc: 0.1840\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 76s - loss: 0.2358 - acc: 0.9868 - val_loss: 2.3251 - val_acc: 0.1830\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 56s - loss: 0.1726 - acc: 0.9927 - val_loss: 2.2913 - val_acc: 0.1880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.models.Sequential at 0x2ab8dfe67860>"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1(tr_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1500 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# add data augmentation image shimage.ImageDataGeneratorGenerator\n",
    "gen_t = image.ImageDataGenerator(rotation_range=15, height_shift_range=0.05, \n",
    "                shear_range=0.1, channel_shift_range=20, width_shift_range=0.1)\n",
    "tr_batches = gen_t.flow_from_directory(train_path, target_size=(224,224), class_mode='categorical', shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yns207/anaconda3/envs/keras-py3/lib/python3.5/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  after removing the cwd from sys.path.\n",
      "/home/yns207/anaconda3/envs/keras-py3/lib/python3.5/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "24/24 [==============================] - 64s - loss: 2.9113 - acc: 0.1138 - val_loss: 2.3154 - val_acc: 0.0900\n",
      "Epoch 2/2\n",
      "24/24 [==============================] - 61s - loss: 2.6070 - acc: 0.1599 - val_loss: 2.3083 - val_acc: 0.1220\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 133s - loss: 2.4072 - acc: 0.2010 - val_loss: 2.3247 - val_acc: 0.1310\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 65s - loss: 2.2894 - acc: 0.2406 - val_loss: 2.3689 - val_acc: 0.1080\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 67s - loss: 2.1034 - acc: 0.2990 - val_loss: 2.4052 - val_acc: 0.1020\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 55s - loss: 2.0475 - acc: 0.3269 - val_loss: 2.4341 - val_acc: 0.1030\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 67s - loss: 1.8624 - acc: 0.3710 - val_loss: 2.4401 - val_acc: 0.1160\n"
     ]
    }
   ],
   "source": [
    "model = conv1(tr_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "24/24 [==============================] - 123s - loss: 1.9066 - acc: 0.3652 - val_loss: 2.4032 - val_acc: 0.1330\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 93s - loss: 1.7616 - acc: 0.4119 - val_loss: 2.3677 - val_acc: 0.1510\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 91s - loss: 1.6931 - acc: 0.4350 - val_loss: 2.2999 - val_acc: 0.1680\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 94s - loss: 1.6599 - acc: 0.4556 - val_loss: 2.2007 - val_acc: 0.2020\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 92s - loss: 1.5929 - acc: 0.4770 - val_loss: 2.1280 - val_acc: 0.2470\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ab8ddbce7b8>"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 0.0001\n",
    "model.fit_generator(tr_batches, \n",
    "                    steps_per_epoch=(tr_batches.n//batch_size)+1, \n",
    "                    validation_data=va_batches, \n",
    "                    validation_steps=(va_batches.n//batch_size)+1,\n",
    "                    epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "24/24 [==============================] - 118s - loss: 1.4795 - acc: 0.5149 - val_loss: 2.0564 - val_acc: 0.3020\n",
      "Epoch 2/25\n",
      "24/24 [==============================] - 97s - loss: 1.4884 - acc: 0.5158 - val_loss: 1.9588 - val_acc: 0.3410\n",
      "Epoch 3/25\n",
      "24/24 [==============================] - 105s - loss: 1.4316 - acc: 0.5251 - val_loss: 1.8608 - val_acc: 0.3720\n",
      "Epoch 4/25\n",
      "24/24 [==============================] - 88s - loss: 1.4046 - acc: 0.5383 - val_loss: 1.8038 - val_acc: 0.3750\n",
      "Epoch 5/25\n",
      "24/24 [==============================] - 92s - loss: 1.3783 - acc: 0.5594 - val_loss: 1.7448 - val_acc: 0.4170\n",
      "Epoch 6/25\n",
      "24/24 [==============================] - 94s - loss: 1.3235 - acc: 0.5855 - val_loss: 1.6832 - val_acc: 0.4540\n",
      "Epoch 7/25\n",
      "24/24 [==============================] - 97s - loss: 1.3069 - acc: 0.5782 - val_loss: 1.6179 - val_acc: 0.4820\n",
      "Epoch 8/25\n",
      "24/24 [==============================] - 85s - loss: 1.2693 - acc: 0.5873 - val_loss: 1.5992 - val_acc: 0.4780\n",
      "Epoch 9/25\n",
      "24/24 [==============================] - 135s - loss: 1.2482 - acc: 0.5896 - val_loss: 1.5411 - val_acc: 0.5080\n",
      "Epoch 10/25\n",
      "24/24 [==============================] - 101s - loss: 1.2451 - acc: 0.5858 - val_loss: 1.5172 - val_acc: 0.5100\n",
      "Epoch 11/25\n",
      "24/24 [==============================] - 92s - loss: 1.1765 - acc: 0.6163 - val_loss: 1.4960 - val_acc: 0.5180\n",
      "Epoch 12/25\n",
      "24/24 [==============================] - 97s - loss: 1.1450 - acc: 0.6322 - val_loss: 1.5162 - val_acc: 0.4990\n",
      "Epoch 13/25\n",
      "24/24 [==============================] - 94s - loss: 1.1510 - acc: 0.6443 - val_loss: 1.4967 - val_acc: 0.5140\n",
      "Epoch 14/25\n",
      "24/24 [==============================] - 88s - loss: 1.0963 - acc: 0.6612 - val_loss: 1.5412 - val_acc: 0.4880\n",
      "Epoch 15/25\n",
      "24/24 [==============================] - 94s - loss: 1.0800 - acc: 0.6593 - val_loss: 1.5114 - val_acc: 0.5150\n",
      "Epoch 16/25\n",
      "24/24 [==============================] - 87s - loss: 1.0406 - acc: 0.6728 - val_loss: 1.5015 - val_acc: 0.5080\n",
      "Epoch 17/25\n",
      "24/24 [==============================] - 90s - loss: 1.0656 - acc: 0.6667 - val_loss: 1.4398 - val_acc: 0.5330\n",
      "Epoch 18/25\n",
      "24/24 [==============================] - 87s - loss: 1.0224 - acc: 0.6819 - val_loss: 1.4228 - val_acc: 0.5550\n",
      "Epoch 19/25\n",
      "24/24 [==============================] - 98s - loss: 1.0096 - acc: 0.6790 - val_loss: 1.4342 - val_acc: 0.5440\n",
      "Epoch 20/25\n",
      "24/24 [==============================] - 91s - loss: 0.9824 - acc: 0.6966 - val_loss: 1.4240 - val_acc: 0.5590\n",
      "Epoch 21/25\n",
      "24/24 [==============================] - 107s - loss: 0.9611 - acc: 0.7068 - val_loss: 1.4010 - val_acc: 0.5650\n",
      "Epoch 22/25\n",
      "24/24 [==============================] - 95s - loss: 0.9442 - acc: 0.7145 - val_loss: 1.4113 - val_acc: 0.5560\n",
      "Epoch 23/25\n",
      "24/24 [==============================] - 92s - loss: 0.9262 - acc: 0.7179 - val_loss: 1.4777 - val_acc: 0.4900\n",
      "Epoch 24/25\n",
      "24/24 [==============================] - 104s - loss: 0.8870 - acc: 0.7238 - val_loss: 1.4675 - val_acc: 0.5010\n",
      "Epoch 25/25\n",
      "24/24 [==============================] - 81s - loss: 0.9087 - acc: 0.7176 - val_loss: 1.4615 - val_acc: 0.5040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ab8ddbce6a0>"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(tr_batches, \n",
    "                    steps_per_epoch=(tr_batches.n//batch_size)+1, \n",
    "                    validation_data=va_batches, \n",
    "                    validation_steps=(va_batches.n//batch_size)+1,\n",
    "                    epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
