{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/cpu:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 10605655448826256541, name: \"/gpu:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 11332668621\n",
       " locality {\n",
       "   bus_id: 2\n",
       " }\n",
       " incarnation: 16019460948262561335\n",
       " physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:85:00.0\"]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os, glob, bcolz\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy import ndimage, misc\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, Input\n",
    "from keras.layers.convolutional import MaxPooling2D, Convolution2D\n",
    "from keras.layers.advanced_activations import PReLU, LeakyReLU\n",
    "\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.inception_v3 import preprocess_input as preprocess_input_incep_xcep\n",
    "from keras.applications.imagenet_utils import preprocess_input as preprocess_input_vgg_resnet\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def read_img(img_path, img_shape):\n",
    "    img = misc.imread(img_path)\n",
    "    img = misc.imresize(img, img_shape)\n",
    "    return img\n",
    "\n",
    "def read_imgs(img_height, img_width):\n",
    "    train_img, test_img = [],[]\n",
    "    for img_path in tqdm(train_set['name'].iloc[:]):\n",
    "        train_img.append(read_img(os.path.join(path, 'train', str(img_path)+'.jpg'), (img_height, img_width)))\n",
    "\n",
    "    for img_path in tqdm(test_set['name'].iloc[:]):\n",
    "        test_img.append(read_img(os.path.join(path, 'test', str(img_path)+'.jpg'), (img_height, img_width)))\n",
    "    return np.array(train_img), np.array(test_img)\n",
    "\n",
    "def save_array(fname, arr):\n",
    "    c=bcolz.carray(arr, rootdir=fname, mode='w')\n",
    "    c.flush()\n",
    "\n",
    "def load_array(fname):\n",
    "    return bcolz.open(fname)[:]\n",
    "\n",
    "def freeze_model(model):\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    return model\n",
    "\n",
    "def grab_optimizer(opt, lr):\n",
    "    if opt == 'sgd':\n",
    "        return optimizers.SGD(lr=lr, decay=1e-6, momentum=0.8, nesterov=True)\n",
    "    elif opt == 'adam':\n",
    "        return optimizers.Adam(lr=lr)\n",
    "    elif opt == 'adagrad':\n",
    "        return optimizers.Adagrad(lr=lr)\n",
    "    elif opt == 'rmsprop':\n",
    "        return optimizers.RMSprop(lr=lr)\n",
    "    \n",
    "def dense_block(units, activation, drop_prob, inputs):\n",
    "    x = Dense(units, activation=None)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activation)(x)\n",
    "    x = Dropout(drop_prob)(x)\n",
    "    return x\n",
    "\n",
    "def make_conv_model(input_shape, optimizer):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    m = conv_block(16, (3,3), (2,2),'relu', inputs=inputs)\n",
    "    m = conv_block(32, (3,3), (2,2), 'relu', inputs=m)\n",
    "    m = conv_block(64, (3,3), (2,2), 'relu', inputs=m)\n",
    "    m = conv_block(128, (3,3), (2,2), 'relu', inputs=m)\n",
    "    m = conv_block(256, (3,3), (2,2), 'relu', inputs=m)\n",
    "    m = Flatten()(m)\n",
    "    m = dense_block(2048, 'relu', 0.25, inputs=m)\n",
    "    m = dense_block(512, 'relu', 0.5, inputs=m)\n",
    "    outputs = dense_block(1, 'sigmoid', 0, inputs=m)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def make_vgg19_conv(input_shape):\n",
    "    base_model = VGG19(input_shape=input_shape, weights='imagenet', include_top=False)\n",
    "    base_model = freeze_model(base_model)\n",
    "    return base_model\n",
    "\n",
    "def make_incepv3_conv(input_shape):\n",
    "    base_model = InceptionV3(input_shape=input_shape, weights='imagenet', include_top=False)\n",
    "    base_model = freeze_model(base_model)\n",
    "    return base_model\n",
    "\n",
    "def make_resnet50_conv(input_shape):\n",
    "    base_model = ResNet50(input_shape=input_shape, weights='imagenet', include_top=False)\n",
    "    base_model = freeze_model(base_model)\n",
    "    return base_model\n",
    "\n",
    "def make_xception_conv(input_shape):\n",
    "    base_model = Xception(input_shape=input_shape, weights='imagenet', include_top=False)\n",
    "    base_model = freeze_model(base_model)\n",
    "    return base_model\n",
    "\n",
    "def make_ft_dense(input_shape, optimizer):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    m = Flatten()(inputs)\n",
    "    m = dense_block(1024, 'relu', 0.25, inputs=m)\n",
    "    m = dense_block(1024, 'relu', 0.5, inputs=m)\n",
    "    outputs = dense_block(1, 'sigmoid', 0, inputs=m)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def make_ft_rand_forest(random_state=100, n_estimators=1000):\n",
    "    return RandomForestClassifier(random_state=random_state, n_jobs=-1, n_estimators=n_estimators)\n",
    "\n",
    "def make_ft_svm():\n",
    "    pass\n",
    "\n",
    "def train_skmodel_ft(model, base_model, train_data, train_label, model_out, model_init_weights, kfolds):\n",
    "    kf = KFold(n_splits=kfolds, shuffle=True)\n",
    "    \n",
    "    i = 0\n",
    "    models_stats = {}\n",
    "    for train_ixs, valid_ixs in kf.split(train_data):\n",
    "        # use convolutional model to precompute training\n",
    "        x_train = train_data[train_ixs]\n",
    "        x_valid = train_data[valid_ixs]\n",
    "        y_train = train_label[train_ixs]\n",
    "        y_valid = train_label[valid_ixs]\n",
    "\n",
    "        x_train = base_model.predict(x_train)\n",
    "        x_valid = base_model.predict(x_valid)\n",
    "\n",
    "        x_train = x_train.reshape((x_train.shape[0], np.prod(x_train.shape[1:])))\n",
    "        x_valid = x_valid.reshape((x_valid.shape[0], np.prod(x_valid.shape[1:])))\n",
    "                \n",
    "        #re-initialzie the weights of the model on each run\n",
    "        model = joblib.load(model_init_weights)\n",
    "        model_out_file = '{}_{}.pkl'.format(model_out, str(i))\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "        joblib.dump(model, model_out_file)\n",
    "        \n",
    "        eval_tr = model.score(x_train, y_train)\n",
    "        eval_va = model.score(x_valid, y_valid)\n",
    "        \n",
    "        tr_score = roc_auc_score(y_train, model.predict(x_train))\n",
    "        va_score = roc_auc_score(y_valid, model.predict(x_valid))\n",
    "        \n",
    "        print('\\n')\n",
    "        print('kfold: {}'.format(str(i)))\n",
    "        print('best model train acc: {}'.format(eval_tr))\n",
    "        print('best model valid acc: {}'.format(eval_va))\n",
    "        print('best model train aroc score: {}, valid aroc score: {}'.format(tr_score, va_score))\n",
    "        print('\\n')\n",
    "        models_stats[model_out_file] = {'score_tr_va':[tr_score, va_score], 'train_acc':[eval_tr], 'val_acc':[eval_va]}\n",
    "        \n",
    "        with open(os.path.join(models_path,'{}_{}.out'.format(model_out,'history')), 'a') as f:\n",
    "            f.write('kfold: {}'.format(str(i)))\n",
    "            f.write('best model train acc: {}'.format(eval_tr))\n",
    "            f.write('best model valid acc: {}'.format(eval_va))\n",
    "            f.write('best model train aroc score: {}, valid aroc score: {}'.format(tr_score, va_score))\n",
    "            f.write('\\n')\n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "    return models_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "setup data dirs and read in imgs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_PATH: /scratch/yns207/data_invasive\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = os.path.join('/scratch', 'yns207', 'data_invasive')\n",
    "\n",
    "path = DATA_DIR\n",
    "test_path = os.path.join(path, 'test')\n",
    "models_path = os.path.join(path, 'results')\n",
    "train_path = os.path.join(path, 'train')\n",
    "valid_path = os.path.join(path, 'valid')\n",
    "print('DATA_PATH: ' + path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(os.path.join(path, 'train_labels.csv'))\n",
    "test_set = pd.read_csv(os.path.join(path, 'sample_submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_img, test_img = read_imgs(300,400)\n",
    "train_label = np.array(train_set['invasive'].iloc[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "create a holdout set of 10%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_img, hold_img, train_labels, hold_labels = train_test_split(train_img, train_label, test_size=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_img.shape, hold_img.shape, train_labels.shape, hold_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "save the datasets unaltered so they can be loaded again at a later point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%cd $models_path\n",
    "save_array('aug_3_train_img.dat', train_img)\n",
    "save_array('aug_3_hold_img.dat', hold_img)\n",
    "save_array('aug_3_train_labels.dat', train_labels)\n",
    "save_array('aug_3_hold_labels.dat', hold_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "read the datasets with bcolz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/yns207/data_invasive/results\n"
     ]
    }
   ],
   "source": [
    "%cd $models_path\n",
    "train_img = load_array('aug_3_train_img.dat')\n",
    "hold_img = load_array('aug_3_hold_img.dat')\n",
    "train_labels = load_array('aug_3_train_labels.dat')\n",
    "hold_labels = load_array('aug_3_hold_labels.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2065, 300, 400, 3), (230, 300, 400, 3), (2065,), (230,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img.shape, hold_img.shape, train_labels.shape, hold_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 100\n",
    "kfolds = 5\n",
    "lr = 0.00025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/yns207/data_invasive/results\n",
      "\n",
      "\n",
      "kfold: 0\n",
      "best model train acc: 1.0\n",
      "best model valid acc: 0.9031476997578692\n",
      "best model train aroc score: 1.0, valid aroc score: 0.8953105196451204\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get it into right folder\n",
    "%cd $models_path\n",
    "model_name = 'invasive_vgg19_rf_aug4'\n",
    "init_weights_model = '{}_base.pkl'.format(model_name)\n",
    "\n",
    "# create base model\n",
    "base_model = make_vgg19_conv(train_img[0].shape)\n",
    "\n",
    "# train dense model ontop of precomputed conv features\n",
    "rand_forest = make_ft_rand_forest(random_state=100, n_estimators=1000)\n",
    "joblib.dump(rand_forest, init_weights_model)\n",
    "\n",
    "#preprocess imgs\n",
    "vgg19_train_img = preprocess_input_vgg_resnet(train_img.astype(np.float32))\n",
    "\n",
    "# train dense model on folds\n",
    "performance = train_skmodel_ft(rand_forest, base_model, vgg19_train_img, train_labels, model_name, init_weights_model, kfolds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get it into right folder\n",
    "%cd $models_path\n",
    "model_name = 'invasive_inceptionv3_rf_aug4'\n",
    "init_weights_model = '{}_base.pkl'.format(model_name)\n",
    "\n",
    "# create base model\n",
    "base_model = make_incepv3_conv(train_img[0].shape)\n",
    "\n",
    "# train dense model ontop of precomputed conv features\n",
    "rand_forest = make_ft_rand_forest(random_state=100, n_estimators=1000)\n",
    "joblib.dump(rand_forest, init_weights_model)\n",
    "\n",
    "#preprocess imgs\n",
    "inceptionv3_train_img = preprocess_input_incep_xcep(train_img.astype(np.float32))\n",
    "\n",
    "# train dense model on folds\n",
    "performance2 = train_skmodel_ft(rand_forest, base_model, inceptionv3_train_img, train_labels, model_name, init_weights_model, kfolds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "performance2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "with proper normalization data aug and some conv retraining should yield very good results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
