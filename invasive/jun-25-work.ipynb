{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "will try:\n",
    "\n",
    "resnet: https://ctmakro.github.io/site/on_learning/resnet_keras.html\n",
    "\n",
    "simplenet: https://arxiv.org/pdf/1608.06037.pdf\n",
    "\n",
    "leaky relu: https://keras.io/layers/advanced-activations/\n",
    "\n",
    "this site has desciptions for voting ensembles, cool: https://mlwave.com/kaggle-ensembling-guide/\n",
    "\n",
    "in combinatio with my convolutional ensemble from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import ndimage\n",
    "from scipy import misc\n",
    "\n",
    "import os, gc, sys, glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, Activation, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.layers import Input, GlobalAveragePooling2D, GlobalMaxPooling2D\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join('/scratch', 'yns207', 'data_invasive')\n",
    "\n",
    "path = DATA_DIR\n",
    "test_path = os.path.join(path, 'test')\n",
    "models_path = os.path.join(path, 'results')\n",
    "train_path = os.path.join(path, 'train')\n",
    "valid_path = os.path.join(path, 'valid')\n",
    "model_name = 'model_jun25_kfold'\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "%cd $DATA_DIR\n",
    "!module load centos/7\n",
    "!7za x '*.7z'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# defining funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grab_optimizer(opt, lr):\n",
    "    if opt == 'sgd':\n",
    "        return optimizers.SGD(lr=lr, decay=1e-6, momentum=0.8, nesterov=True)\n",
    "    elif opt == 'adam':\n",
    "        return optimizers.Adam(lr=lr)\n",
    "    elif opt == 'adagrad':\n",
    "        return optimizers.Adagrad(lr=lr)\n",
    "    elif opt == 'rmsprop':\n",
    "        return optimizers.RMSprop(lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dense_block(units, activation, drop_prob, inputs):\n",
    "    x = BatchNormalization()(inputs)\n",
    "    x = Dense(units, activation=activation)(x)\n",
    "    x = Dropout(drop_prob)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#my attempt at making a resnet identity block, wont be making any conv block\n",
    "def resnet_block(filter_depth, filter_size, pool_size, activation, inputs):\n",
    "    x = BatchNormalization()(inputs)\n",
    "    x = Convolution2D(filter_depth, (1,1), activation=activation)(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Convolution2D(filter_depth, filter_size, activation=activation, padding='same')(x)\n",
    "    \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Convolution2D(filter_depth, (1,1))(x)\n",
    "    \n",
    "    shortcut = Convolution2D(filter_depth, (1,1))(inputs)\n",
    "    shortcut = BatchNormalization()(shortcut)\n",
    "    \n",
    "    x = keras.layers.add([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_model(input_shape, optimizer):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    m = ZeroPadding2D((3,3))(inputs)\n",
    "    m = Convolution2D(16, (3,3), strides=(2,2), activation='relu')(m)\n",
    "    m = MaxPooling2D((3,3), strides=(2,2))(m)\n",
    "    m = resnet_block(32, (3,3), (2,2), 'relu', inputs=m)\n",
    "    m = resnet_block(64, (3,3), (2,2), 'relu', inputs=m)\n",
    "    m = resnet_block(128, (3,3), (2,2), 'relu', inputs=m)\n",
    "    m = AveragePooling2D((7, 7))(m)\n",
    "    m = Flatten()(m)\n",
    "    m = dense_block(2048, 'relu', 0.25, inputs=m)\n",
    "    m = dense_block(512, 'relu', 0.5, inputs=m)\n",
    "    outputs = dense_block(1, 'sigmoid', 0, inputs=m)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_preds(model, test_data):\n",
    "    # worth leaving a note:\n",
    "    # prediction 1,2,3 from jun21 had misalgined the test names\n",
    "    # also submission file 3 and 4 for jun21 are actually both rubmission 4 (accident)\n",
    "    preds = model.predict(test_data).flatten()\n",
    "    subm = test_set.copy()\n",
    "    subm['invasive'] = preds\n",
    "    return subm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(os.path.join(path, 'train_labels.csv'))\n",
    "test_set = pd.read_csv(os.path.join(path, 'sample_submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_set.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#img_shape should eb tuple\n",
    "#(H,W), height, width\n",
    "def read_img(img_path, img_shape):\n",
    "    img = misc.imread(img_path)\n",
    "    img = misc.imresize(img, img_shape)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_imgs(img_height, img_width):\n",
    "    train_img, test_img = [],[]\n",
    "    for img_path in tqdm(train_set['name'].iloc[:]):\n",
    "        train_img.append(read_img(os.path.join(path, 'train', str(img_path)+'.jpg'), (img_height, img_width)))\n",
    "\n",
    "    for img_path in tqdm(test_set['name'].iloc[:]):\n",
    "        test_img.append(read_img(os.path.join(path, 'test', str(img_path)+'.jpg'), (img_height, img_width)))\n",
    "\n",
    "    train_img = np.array(train_img, np.float32)/255\n",
    "    test_img = np.array(test_img, np.float32)/255\n",
    "    train_label = np.array(train_set['invasive'].iloc[:])\n",
    "    \n",
    "    return train_img, test_img, train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img, test_img, train_label = read_imgs(300,400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(misc.imresize(train_img[124], (300,400)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd $DATA_DIR\n",
    "def train_model_k_folds(model, train_data, train_label, model_out,  model_init_weights, epochs, kfolds):\n",
    "    batch_size = 32\n",
    "    kf = model_selection.KFold(n_splits=kfolds, shuffle=True)\n",
    "    score_func = metrics.roc_auc_score\n",
    "\n",
    "    i = 0\n",
    "    models_stats = {}\n",
    "    for train_ixs, valid_ixs in kf.split(train_data):\n",
    "        x_train = train_data[train_ixs]\n",
    "        x_valid = train_data[valid_ixs]\n",
    "        y_train = train_label[train_ixs]\n",
    "        y_valid = train_label[valid_ixs]\n",
    "\n",
    "        gen = ImageDataGenerator(\n",
    "            rotation_range = 30,\n",
    "            width_shift_range = 0.2,\n",
    "            height_shift_range = 0.2,\n",
    "            shear_range = 0.2,\n",
    "            zoom_range = 0.2,\n",
    "            horizontal_flip = True,\n",
    "            vertical_flip = True,\n",
    "            fill_mode = 'nearest')\n",
    "        \n",
    "        #re-initialzie the weights of the model on each run\n",
    "        model.load_weights(model_init_weights)\n",
    "        model_out_file = '/scratch/yns207/data_invasive/{}_{}.model'.format(model_out, str(i))\n",
    "        model_checkpoint = ModelCheckpoint(model_out_file, \n",
    "                                            monitor='val_loss', \n",
    "                                            save_best_only=True)\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=25, verbose=1, mode='auto')\n",
    "\n",
    "        hist = model.fit_generator(gen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                            steps_per_epoch=(len(x_train)//batch_size)+1,\n",
    "                            validation_data=(x_valid,y_valid),\n",
    "                            validation_steps=(len(x_valid)//batch_size)+1,\n",
    "                            epochs=epochs,\n",
    "                            verbose=1,\n",
    "                            callbacks=[early_stopping, model_checkpoint])\n",
    "        \n",
    "        model.load_weights(model_out_file)\n",
    "        \n",
    "        eval_tr = model.evaluate(x_train, y_train)\n",
    "        eval_va = model.evaluate(x_valid, y_valid)\n",
    "        \n",
    "        tr_score = score_func(y_train, model.predict(x_train)[:, 0])\n",
    "        va_score = score_func(y_valid, model.predict(x_valid)[:, 0])\n",
    "        \n",
    "        print('\\n')\n",
    "        print('kfold: {}'.format(str(i)))\n",
    "        print('best model train acc: {}, loss: {}'.format(eval_tr[1], eval_tr[0]))\n",
    "        print('best model valid acc: {}, loss: {}'.format(eval_va[1], eval_va[0]))\n",
    "        print('best model train aroc score: {}, valid aroc score: {}'.format(tr_score, va_score))\n",
    "        print('\\n')\n",
    "        models_stats[model_out_file] = {'score_tr_va':[tr_score, va_score], 'train_acc_loss':[eval_tr[1], eval_tr[0]], 'val_acc_loss':[eval_va[1], eval_va[0]]}\n",
    "        i += 1\n",
    "        \n",
    "    return models_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model((300,400,3), grab_optimizer('adam', 0.00025))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save initial weights for use on each kfolds run\n",
    "model.save_weights('{}_base.model'.format(model_name))\n",
    "# run kfolds 10x\n",
    "models_stats = train_model_k_folds(model, train_img, train_label, model_name, '{}_base.model'.format(model_name), 100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok this doesnt look so bad. lets do what we did before, take 3-4 good models and make an ensemble. \n",
    "\n",
    "\n",
    "model_jun25_kfold_7.model\n",
    "\n",
    "{'score_tr_va': [0.99910285359237438,0.99650904474769919],\n",
    "  'train_acc_loss': [0.98209099709583736, 0.055329413934892976],\n",
    "  'val_acc_loss': [0.95196506576246565, 0.088502192666436913]}\n",
    "\n",
    "model_jun25_kfold_6.model\n",
    "\n",
    "{'score_tr_va': [0.99870266114630291,\n",
    "   0.99662337662337663],\n",
    "  'train_acc_loss': [0.98886737634228594, 0.043189480468010508],\n",
    "  'val_acc_loss': [0.96506550218340614, 0.072713479034167486]}\n",
    "\n",
    "model_jun25_kfold_5.model\n",
    "\n",
    "{'score_tr_va': [0.9972994601947901,\n",
    "   0.99728217426059151],\n",
    "  'train_acc_loss': [0.97967086156824779, 0.063989531331752419],\n",
    "  'val_acc_loss': [0.95633187772925765, 0.083368520903112323]}\n",
    "\n",
    "model_jun25_kfold_4.model\n",
    "\n",
    "{'score_tr_va': [0.99884112767346811,\n",
    "   0.99765826873385011],\n",
    "  'train_acc_loss': [0.98595641646489107, 0.045430601223148674],\n",
    "  'val_acc_loss': [0.97826086956521741, 0.057762287557125092]}\n",
    "  \n",
    "model_jun25_kfold_3.model\n",
    "\n",
    "{'score_tr_va': [0.99880816487589419,\n",
    "   0.9979615133724723],\n",
    "  'train_acc_loss': [0.98111380145278448, 0.056782990755382519],\n",
    "  'val_acc_loss': [0.97391304347826091, 0.080385985452195871]},\n",
    " '/scratch/yns207/data_invasive/model_jun25_kfold_4.model': {'\n",
    "\n",
    "model_jun25_kfold_1.model\n",
    "\n",
    "{'score_tr_va': [0.99906311787072244,\n",
    "   0.9931013099759709],\n",
    "  'train_acc_loss': [0.98595641646489107, 0.044911352720012385],\n",
    "  'val_acc_loss': [0.9652173913043478, 0.096299015989770059]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm = test_set.iloc[:]\n",
    "subm = subm.drop('invasive',1)\n",
    "\n",
    "%cd $DATA_DIR\n",
    "models = [1,3,4,5,6,7]\n",
    "model = make_model((300,400,3), grab_optimizer('adam', 0.00025))\n",
    "\n",
    "for f in models:\n",
    "    model.load_weights('{}_{}.model'.format(model_name, str(f)))\n",
    "    subm[str(f)] = make_preds(model, test_img)['invasive']\n",
    "subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm['invasive'] = subm[[str(f) for f in models]].mean(axis=1)\n",
    "subm = subm.drop([str(f) for f in models], 1)\n",
    "subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm.to_csv(os.path.join(DATA_DIR, 'results', 'subm_jun_27_17_0.gz'), index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "that scored a 0.984 (less than my current 0.985) maybe if we jack it up with another layer we'll improve the score. or we could try rank averaging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import rankdata\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subm = test_set.iloc[:]\n",
    "subm = subm.drop('invasive',1)\n",
    "\n",
    "%cd $DATA_DIR\n",
    "models = [1,3,4,5,6,7]\n",
    "model = make_model((300,400,3), grab_optimizer('adam', 0.00025))\n",
    "\n",
    "for f in models:\n",
    "    model.load_weights('{}_{}.model'.format(model_name, str(f)))\n",
    "    subm[str(f)] = make_preds(model, test_img)['invasive']\n",
    "subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in models:\n",
    "    subm['r'+str(f)] = rankdata(subm[str(f)])\n",
    "subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm['r_avg'] = subm[['r1','r3','r4','r5','r6','r7']].mean(axis=1)\n",
    "subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm['final_r_blend'] = MinMaxScaler().fit_transform(subm['r_avg'].reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm = subm[['name', 'final_r_blend']]\n",
    "subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm.to_csv(os.path.join(DATA_DIR, 'results', 'subm_jun_27_17_1.gz'), index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok that had the exact same 0.984 score, LOL that's because the submission NEVER WENT THROUGH, i accidentally submitted the older file, my mistake, if it had gone through the column name is not invasive here so it would haev trhown an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd $DATA_DIR\n",
    "_, test_img_22, _ = read_imgs(128,128)\n",
    "_, test_img_23_24, _ = read_imgs(300,400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lets try one more ensemble with 3 best conv models, the 3 best resnet models\n",
    "\n",
    "subm = test_set.iloc[:]\n",
    "subm = subm.drop('invasive',1)\n",
    "\n",
    "# 3 best conv models,\n",
    "# best resnet models, (omitting model 1)\n",
    "models = [\n",
    "        'model_jun23_kfold_3.model',\n",
    "        'model_jun23_kfold_7.model',\n",
    "        'model_jun23_kfold_9.model',\n",
    "        'model_jun25_kfold_3.model',\n",
    "        'model_jun25_kfold_4.model',\n",
    "        'model_jun25_kfold_5.model',\n",
    "        'model_jun25_kfold_6.model',\n",
    "        'model_jun25_kfold_7.model'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(filter_depth, filter_size, pool_size, activation, inputs):\n",
    "    x = BatchNormalization()(inputs)\n",
    "    x = Convolution2D(filter_depth, filter_size, activation=activation)(x)\n",
    "    x = MaxPooling2D(pool_size=pool_size)(x)\n",
    "    return x\n",
    "\n",
    "def dense_block(units, activation, drop_prob, inputs):\n",
    "    x = BatchNormalization()(inputs)\n",
    "    x = Dense(units, activation=activation)(x)\n",
    "    x = Dropout(drop_prob)(x)\n",
    "    return x\n",
    "\n",
    "def make_model_23(input_shape, optimizer):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    m = conv_block(16, (3,3), (2,2),'relu', inputs=inputs)\n",
    "    m = conv_block(32, (3,3), (2,2), 'relu', inputs=m)\n",
    "    m = conv_block(64, (3,3), (2,2), 'relu', inputs=m)\n",
    "    m = conv_block(128, (3,3), (2,2), 'relu', inputs=m)\n",
    "    m = conv_block(256, (3,3), (2,2), 'relu', inputs=m)\n",
    "    m = Flatten()(m)\n",
    "    m = dense_block(2048, 'relu', 0.25, inputs=m)\n",
    "    m = dense_block(512, 'relu', 0.5, inputs=m)\n",
    "    outputs = dense_block(1, 'sigmoid', 0, inputs=m)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def conv_block(filter_depth, filter_size, pool_size, activation, inputs):\n",
    "    x = BatchNormalization()(inputs)\n",
    "    x = Convolution2D(filter_depth, filter_size, activation=activation)(x)\n",
    "    x = MaxPooling2D(pool_size=pool_size)(x)\n",
    "    return x\n",
    "\n",
    "def dense_block(units, activation, drop_prob, inputs):\n",
    "    x = BatchNormalization()(inputs)\n",
    "    x = Dense(units, activation=activation)(x)\n",
    "    x = Dropout(drop_prob)(x)\n",
    "    return x\n",
    "\n",
    "def make_model_22(input_shape, optimizer):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    m = conv_block(16, (3,3), (2,2),'relu', inputs=inputs)\n",
    "    m = conv_block(32, (3,3), (2,2), 'relu', inputs=m)\n",
    "    m = conv_block(64, (3,3), (2,2), 'relu', inputs=m)\n",
    "    m = conv_block(128, (3,3), (2,2), 'relu', inputs=m)\n",
    "    m = Flatten()(m)\n",
    "    m = dense_block(2048, 'relu', 0.55, inputs=m)\n",
    "    m = dense_block(512, 'relu', 0.65, inputs=m)\n",
    "    outputs = dense_block(1, 'sigmoid', 0, inputs=m)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def dense_block(units, activation, drop_prob, inputs):\n",
    "    x = BatchNormalization()(inputs)\n",
    "    x = Dense(units, activation=activation)(x)\n",
    "    x = Dropout(drop_prob)(x)\n",
    "    return x\n",
    "\n",
    "#my attempt at making a resnet identity block, wont be making any conv block\n",
    "def resnet_block(filter_depth, filter_size, pool_size, activation, inputs):\n",
    "    x = BatchNormalization()(inputs)\n",
    "    x = Convolution2D(filter_depth, (1,1), activation=activation)(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Convolution2D(filter_depth, filter_size, activation=activation, padding='same')(x)\n",
    "    \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Convolution2D(filter_depth, (1,1))(x)\n",
    "    \n",
    "    shortcut = Convolution2D(filter_depth, (1,1))(inputs)\n",
    "    shortcut = BatchNormalization()(shortcut)\n",
    "    \n",
    "    x = keras.layers.add([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def make_model_25(input_shape, optimizer):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    m = ZeroPadding2D((3,3))(inputs)\n",
    "    m = Convolution2D(16, (3,3), strides=(2,2), activation='relu')(m)\n",
    "    m = MaxPooling2D((3,3), strides=(2,2))(m)\n",
    "    m = resnet_block(32, (3,3), (2,2), 'relu', inputs=m)\n",
    "    m = resnet_block(64, (3,3), (2,2), 'relu', inputs=m)\n",
    "    m = resnet_block(128, (3,3), (2,2), 'relu', inputs=m)\n",
    "    m = AveragePooling2D((7, 7))(m)\n",
    "    m = Flatten()(m)\n",
    "    m = dense_block(2048, 'relu', 0.25, inputs=m)\n",
    "    m = dense_block(512, 'relu', 0.5, inputs=m)\n",
    "    outputs = dense_block(1, 'sigmoid', 0, inputs=m)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "#omitted 24 because it was just a poorly performing resnet50\n",
    "model_23 = make_model_23((300,400,3), grab_optimizer('adam', 0.000125))\n",
    "model_25 = make_model_25((300,400,3), grab_optimizer('adam', 0.0005))\n",
    "\n",
    "for f in models:\n",
    "    if 'jun23' in f:\n",
    "        model_23.load_weights(f)\n",
    "        model_test = model_23\n",
    "        subm[str(f)] = make_preds(model_test, test_img_23_24)['invasive']\n",
    "    else:\n",
    "        model_25.load_weights(f)\n",
    "        model_test = model_25\n",
    "        subm[str(f)] = make_preds(model_test, test_img_23_24)['invasive']\n",
    "subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in models:\n",
    "    subm['r_'+str(f)] = rankdata(subm[str(f)])\n",
    "subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm['r_avg'] = subm[['r_'+f for f in models]].mean(axis=1)\n",
    "subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm['final_r_blend'] = MinMaxScaler().fit_transform(subm['r_avg'].reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm = subm[['name', 'final_r_blend']]\n",
    "subm.columns = ['name', 'invasive']\n",
    "subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm.to_csv(os.path.join(DATA_DIR, 'results', 'subm_jun_27_17_2.gz'), index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alright well that rank average did improve my score, 0.98526 -> 0.98560, this ensemble is maybe worth building off of."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# summary\n",
    "\n",
    "http://blog.kaggle.com/2017/04/20/dogs-vs-cats-redux-playground-competition-3rd-place-interview-marco-lugo/\n",
    "\n",
    "https://gogul09.github.io/software/flower-recognition\n",
    "\n",
    "good overview of voting/rank averraging ensembles:\n",
    "\n",
    "http://andremeetsdata.com/2015/12/30/Numerai-Averaging\n",
    "\n",
    "https://mlwave.com/kaggle-ensembling-guide/\n",
    "\n",
    "https://www.kaggle.com/c/homesite-quote-conversion/discussion/18067\n",
    "\n",
    "giving extra number after the decimal may hust us? worth investigating, or it could have no effect on receiver curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
