{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/cpu:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 2971641885611843514, name: \"/gpu:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 11332668621\n",
       " locality {\n",
       "   bus_id: 2\n",
       " }\n",
       " incarnation: 15488722034800260466\n",
       " physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:84:00.0\"]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import ndimage\n",
    "from scipy import misc\n",
    "\n",
    "import os, gc, sys, glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.layers import Input, GlobalAveragePooling2D, GlobalMaxPooling2D\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/yns207/data_invasive\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = os.path.join('/scratch', 'yns207', 'data_invasive')\n",
    "\n",
    "path = DATA_DIR\n",
    "test_path = os.path.join(path, 'test')\n",
    "models_path = os.path.join(path, 'results')\n",
    "train_path = os.path.join(path, 'train')\n",
    "valid_path = os.path.join(path, 'valid')\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%cd $DATA_DIR\n",
    "!module load centos/7\n",
    "!7za x '*.7z'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# defining funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_block(filter_depth, filter_size, pool_size, activation, inputs):\n",
    "    x = Convolution2D(filter_depth, filter_size, activation=activation)(inputs)\n",
    "    x = MaxPooling2D(pool_size=pool_size)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dense_block(units, activation, drop_prob, inputs):\n",
    "    x = Dense(units, activation=activation)(inputs)\n",
    "    x = Dropout(drop_prob)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output_block(units, activation, inputs):\n",
    "    x = Dense(units, activation=activation)(inputs)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grab_optimizer(opt, lr):\n",
    "    if opt == 'sgd':\n",
    "        return optimizers.SGD(lr=lr, decay=1e-6, momentum=0.8, nesterov=True)\n",
    "    elif opt == 'adam':\n",
    "        return optimizers.Adam(lr=lr)\n",
    "    elif opt == 'adagrad':\n",
    "        return optimizers.Adagrad(lr=lr)\n",
    "    elif opt == 'rmsprop':\n",
    "        return optimizers.RMSprop(lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_model1(input_shape, optimizer):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    m = conv_block(16, (3,3), (2,2),'relu', inputs=inputs)\n",
    "    m = conv_block(32, (3,3), (2,2), 'relu', inputs=m)\n",
    "    m = conv_block(64, (3,3), (2,2), 'relu', inputs=m)\n",
    "    m = conv_block(128, (3,3), (2,2), 'relu', inputs=m)\n",
    "    m = Flatten()(m)\n",
    "    m = dense_block(2048, 'relu', 0.55, inputs=m)\n",
    "    m = dense_block(512, 'relu', 0.65, inputs=m)\n",
    "    outputs = dense_block(1, 'sigmoid', 0, inputs=m)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_preds(model, test_data):\n",
    "    # worth leaving a note:\n",
    "    # prediction 1,2,3 from jun21 had misalgined the test names\n",
    "    # also submission file 3 and 4 for jun21 are actually both rubmission 4 (accident)\n",
    "    preds = model.predict(test_data).flatten()\n",
    "    subm = test_set.copy()\n",
    "    subm['invasive'] = preds\n",
    "    return subm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(os.path.join(path, 'train_labels.csv'))\n",
    "test_set = pd.read_csv(os.path.join(path, 'sample_submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>invasive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name  invasive\n",
       "0     1         0\n",
       "1     2         0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#img_shape should eb tuple\n",
    "#(H,W), height, width\n",
    "def read_img(img_path, img_shape):\n",
    "    img = misc.imread(img_path)\n",
    "    img = misc.imresize(img, img_shape)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_imgs(img_height, img_width):\n",
    "    train_img, test_img = [],[]\n",
    "    for img_path in tqdm(train_set['name'].iloc[:]):\n",
    "        train_img.append(read_img(os.path.join(path, 'train', str(img_path)+'.jpg'), (img_height, img_width)))\n",
    "\n",
    "    for img_path in tqdm(test_set['name'].iloc[:]):\n",
    "        test_img.append(read_img(os.path.join(path, 'test', str(img_path)+'.jpg'), (img_height, img_width)))\n",
    "\n",
    "    train_img = np.array(train_img, np.float32)/255\n",
    "    test_img = np.array(test_img, np.float32)/255\n",
    "    train_label = np.array(train_set['invasive'].iloc[:])\n",
    "    \n",
    "    return train_img, test_img, train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_img, test_img, train_label = read_imgs((128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(misc.imresize(train_img[0], (300,400)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = model_selection.train_test_split(train_img, train_label, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try a few rounds of training\n",
    "model = make_model1((128,128,3), grab_optimizer('sgd', 0.01))\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=7, verbose=1, mode='auto')\n",
    "\n",
    "gen = ImageDataGenerator(\n",
    "    rotation_range = 30,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True,\n",
    "    vertical_flip = True,\n",
    "    fill_mode = 'nearest')\n",
    "\n",
    "# only required of featurewise center or zca whitening or a few other things\n",
    "# gen.fit(x_train)\n",
    "\n",
    "hist = model.fit_generator(gen.flow(x_train, y_train, batch_size=64),\n",
    "                    steps_per_epoch=(len(x_train)//64) + 1,\n",
    "                    validation_data=(x_valid,y_valid),\n",
    "                    validation_steps=(len(x_valid)//64)+1,\n",
    "                    epochs=25,\n",
    "                    verbose=2,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok that seems to work, now lets try some k folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ok now lets try a k folds\n",
    "\n",
    "def train_model_k_folds(model, train_data, train_label, model_out, epochs, kfolds):\n",
    "    kf = model_selection.KFold(n_splits=kfolds, shuffle=True)\n",
    "    score_func = metrics.roc_auc_score\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    for train_ixs, valid_ixs in kf.split(train_data):\n",
    "        x_train = train_data[train_ixs]\n",
    "        x_valid = train_data[valid_ixs]\n",
    "        y_train = train_label[train_ixs]\n",
    "        y_valid = train_label[valid_ixs]\n",
    "\n",
    "        gen = ImageDataGenerator(\n",
    "            rotation_range = 30,\n",
    "            width_shift_range = 0.2,\n",
    "            height_shift_range = 0.2,\n",
    "            shear_range = 0.2,\n",
    "            zoom_range = 0.2,\n",
    "            horizontal_flip = True,\n",
    "            vertical_flip = True,\n",
    "            fill_mode = 'nearest')\n",
    "\n",
    "        # only required of featurewise center or zca whitening or a few other things\n",
    "        # gen.fit(x_train)\n",
    "        \n",
    "        model.reset_states() \n",
    "        \n",
    "        model_checkpoint = ModelCheckpoint('/scratch/yns207/data_invasive/{}_{}.model'.format(model_out, str(i)), \n",
    "                                            monitor='val_loss', \n",
    "                                            save_best_only=True)\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=7, verbose=1, mode='auto')\n",
    "\n",
    "        hist = model.fit_generator(gen.flow(x_train, y_train, batch_size=64),\n",
    "                            steps_per_epoch=(len(x_train)//64) + 1,\n",
    "                            validation_data=(x_valid,y_valid),\n",
    "                            validation_steps=(len(x_valid)//64)+1,\n",
    "                            epochs=epochs,\n",
    "                            verbose=1,\n",
    "                            callbacks=[early_stopping, model_checkpoint])\n",
    "        \n",
    "        model.load_weights('/scratch/yns207/data_invasive/{}_{}.model'.format(model_out, str(i)))\n",
    "        \n",
    "        eval_tr = model.evaluate(x_train, y_train)\n",
    "        eval_va = model.evaluate(x_valid, y_valid)\n",
    "        \n",
    "        tr_score = score_func(y_train, model.predict(x_train)[:, 0])\n",
    "        va_score = score_func(y_valid, model.predict(x_valid)[:, 0])\n",
    "        \n",
    "        print('kfold: {}'.format(str(i)))\n",
    "        print('best model train acc: {}, loss: {}'.format(eval_tr[1], eval_tr[0]))\n",
    "        print('best model valid acc: {}, loss: {}'.format(eval_va[1], eval_va[0]))\n",
    "        print('best model train aroc score: {}, valid aroc score: {}'.format(tr_score, va_score))\n",
    "        print('\\n')\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# i changed the code a bit so this just reprsents how to run the original jun21_4 submission\n",
    "model = make_model1((128,128,3), grab_optimizer('sgd', 0.005))\n",
    "train_model_k_folds(model, train_img, 'model_jun21_kfold', 50, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# befori methodized it. so no longer valid is this\n",
    "# this is actually using the final weights per epoch and we want the best weights for each epoch so\n",
    "# lets load them for each and calculate area under roc curve\n",
    "# this is wrong. this whole cell is wrong because i reloaded the test/train data and its df everytime so we probably evaluate\n",
    "#mdoel 6 based on data it was trained on...not the original witheld valid data.\n",
    "%cd $DATA_DIR\n",
    "g = glob.glob('model_jun21_kfold_*.model')\n",
    "\n",
    "model = make_model((128,128,3), grab_optimizer('sgd', 0.005))\n",
    "x_train, x_valid, y_train, y_valid = model_selection.train_test_split(train_img, train_label, test_size=0.20)\n",
    "\n",
    "for f in g:\n",
    "    model.load_weights(f)\n",
    "    tr_score = score_func(y_train, model.predict(x_train)[:, 0])\n",
    "    va_score = score_func(y_valid, model.predict(x_valid)[:, 0])\n",
    "    print('model: {}'.format(f))\n",
    "    print('tr score: {}, va score: {}'.format(tr_score, va_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# summary\n",
    "\n",
    "it looks like model 6 did the best here so we should try to use model 6 to mak ea predictions on the test set or maybe one of the other onef like model 4 or model 9 provide lower validation area under roc but will generalize better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%cd $DATA_DIR\n",
    "model = make_model((128,128,3), grab_optimizer('sgd', 0.005))\n",
    "model.load_weights('model_jun21_kfold_6.model')\n",
    "subm = make_preds(model, test_img)\n",
    "subm.to_csv(os.path.join(DATA_DIR, 'results', 'subm_june_21_2017_4.gz'), index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cool submission 4 had a score of 0.95 on the leader board"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok so my plan is do one round of training with 128x128\n",
    "then one with 225x300 \n",
    "then one with 450x600\n",
    "for every kfold.\n",
    "these should all maintain aspect ratio\n",
    "\n",
    "lets try 2 training rounds one on small images, one on bigger images\n",
    "\n",
    "\n",
    "we cannot do multiple rounds of training with dif image sizes, figure out why that worked/improved vgg before..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok that wasnt better than the 128x128 (deleted it) 10 fold kfold best model score final score, if got us 0.958 lower than my current 0.959, i want to try ensembling all the models in the original 10-fold cross validation. basically take an average and see what that does for us. ok so i didnt really do the kfolds right. what i should have done is: for each k fold when we train it mak epredictions on its test set, as we go through all the k folds we need to predict for each fold's test set the results, then use those results. instead of just picking the best model. bu actually since we didnt touch our test data at all in the kfolds (we generated folds from train_imgs only) we can use the stored models to make a prediction about the actual test set labels, ok actually we cant because trintest split works randomly and weve restarted the kernel since then. nvm we didnt pass in the test data. so what we have are 10 models, trained on dif segments of the training data which we can now combine to make a prediction about the held off test set. so we can for each tding in the test set mak ea prediction using each model, then avg them for the final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2295/2295 [01:14<00:00, 30.93it/s]\n",
      "100%|██████████| 1531/1531 [00:48<00:00, 31.46it/s]\n"
     ]
    }
   ],
   "source": [
    "train_img, test_img, train_label = read_imgs(128,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/yns207/data_invasive\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>model_jun21_kfold_6.model</th>\n",
       "      <th>model_jun21_kfold_0.model</th>\n",
       "      <th>model_jun21_kfold_7.model</th>\n",
       "      <th>model_jun21_kfold_2.model</th>\n",
       "      <th>model_jun21_kfold_1.model</th>\n",
       "      <th>model_jun21_kfold_9.model</th>\n",
       "      <th>model_jun21_kfold_5.model</th>\n",
       "      <th>model_jun21_kfold_3.model</th>\n",
       "      <th>model_jun21_kfold_4.model</th>\n",
       "      <th>model_jun21_kfold_8.model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.996251</td>\n",
       "      <td>0.990665</td>\n",
       "      <td>0.991979</td>\n",
       "      <td>0.992946</td>\n",
       "      <td>0.995229</td>\n",
       "      <td>0.992048</td>\n",
       "      <td>0.986676</td>\n",
       "      <td>0.984660</td>\n",
       "      <td>0.997173</td>\n",
       "      <td>0.993619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.115335</td>\n",
       "      <td>0.096591</td>\n",
       "      <td>0.189778</td>\n",
       "      <td>0.114597</td>\n",
       "      <td>0.172190</td>\n",
       "      <td>0.112734</td>\n",
       "      <td>0.218326</td>\n",
       "      <td>0.141875</td>\n",
       "      <td>0.096810</td>\n",
       "      <td>0.115411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.150518</td>\n",
       "      <td>0.104988</td>\n",
       "      <td>0.202259</td>\n",
       "      <td>0.121986</td>\n",
       "      <td>0.151940</td>\n",
       "      <td>0.115175</td>\n",
       "      <td>0.278470</td>\n",
       "      <td>0.158022</td>\n",
       "      <td>0.098422</td>\n",
       "      <td>0.175202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.102934</td>\n",
       "      <td>0.118156</td>\n",
       "      <td>0.256066</td>\n",
       "      <td>0.134449</td>\n",
       "      <td>0.259272</td>\n",
       "      <td>0.116221</td>\n",
       "      <td>0.262410</td>\n",
       "      <td>0.190198</td>\n",
       "      <td>0.101841</td>\n",
       "      <td>0.138025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.994810</td>\n",
       "      <td>0.992621</td>\n",
       "      <td>0.940180</td>\n",
       "      <td>0.988019</td>\n",
       "      <td>0.941458</td>\n",
       "      <td>0.993243</td>\n",
       "      <td>0.944794</td>\n",
       "      <td>0.925843</td>\n",
       "      <td>0.976860</td>\n",
       "      <td>0.992455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name  model_jun21_kfold_6.model  model_jun21_kfold_0.model  \\\n",
       "0     1                   0.996251                   0.990665   \n",
       "1     2                   0.115335                   0.096591   \n",
       "2     3                   0.150518                   0.104988   \n",
       "3     4                   0.102934                   0.118156   \n",
       "4     5                   0.994810                   0.992621   \n",
       "\n",
       "   model_jun21_kfold_7.model  model_jun21_kfold_2.model  \\\n",
       "0                   0.991979                   0.992946   \n",
       "1                   0.189778                   0.114597   \n",
       "2                   0.202259                   0.121986   \n",
       "3                   0.256066                   0.134449   \n",
       "4                   0.940180                   0.988019   \n",
       "\n",
       "   model_jun21_kfold_1.model  model_jun21_kfold_9.model  \\\n",
       "0                   0.995229                   0.992048   \n",
       "1                   0.172190                   0.112734   \n",
       "2                   0.151940                   0.115175   \n",
       "3                   0.259272                   0.116221   \n",
       "4                   0.941458                   0.993243   \n",
       "\n",
       "   model_jun21_kfold_5.model  model_jun21_kfold_3.model  \\\n",
       "0                   0.986676                   0.984660   \n",
       "1                   0.218326                   0.141875   \n",
       "2                   0.278470                   0.158022   \n",
       "3                   0.262410                   0.190198   \n",
       "4                   0.944794                   0.925843   \n",
       "\n",
       "   model_jun21_kfold_4.model  model_jun21_kfold_8.model  \n",
       "0                   0.997173                   0.993619  \n",
       "1                   0.096810                   0.115411  \n",
       "2                   0.098422                   0.175202  \n",
       "3                   0.101841                   0.138025  \n",
       "4                   0.976860                   0.992455  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm = test_set.iloc[:]\n",
    "subm = subm.drop('invasive',1)\n",
    "\n",
    "%cd $DATA_DIR\n",
    "g = glob.glob('model_jun21_kfold_*.model')\n",
    "\n",
    "model = make_model1((128,128,3), grab_optimizer('sgd', 0.005))\n",
    "\n",
    "for f in g:\n",
    "    model.load_weights(f)\n",
    "    subm[f] = make_preds(model, test_img)['invasive']\n",
    "    \n",
    "subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm['invasive'] = subm[[f for f in g]].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm = subm.drop([f for f in g],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>invasive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.992125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.137365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.155698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.167957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.969028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name  invasive\n",
       "0     1  0.992125\n",
       "1     2  0.137365\n",
       "2     3  0.155698\n",
       "3     4  0.167957\n",
       "4     5  0.969028"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm.to_csv(os.path.join(DATA_DIR, 'results', 'subm_jun22_17_1.gz'), index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok so this ensiemble actually made the score worse 0.952 instaed of 0.959"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REMINDER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when you change models or whatever move to an ew notebook, porbably nned a new one veery day. you keep changing things and its messing up stored weights. like adding batch norm and zero padding to layers that didnt have it. what im gonna do is revert this to its pure state (what it did before) then make a copy and do stuff in a new notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
